Summarization of Carroll and Green - Mathematical Tools for Applied Multivariate Analysis, 1997

Author: Roxana Tesileanu
Date: September 2017

Ch.1 - The Nature of Multivariate Data Analysis

Multivariate techniques are useful for:
- discovering regularities in the behavior of two or more variables
- testing alternative models of association between two or more variables, including the determination of whether and how two or more groups (or other entities) differ in their multivariate profiles.

Multivariate analysis is concerned with both the discovery and testing of patterns in associative data.

- characteristics of objects are measured: MULTIVARIATE ANALYSIS IS CONCERNED WITH ASSOCIATION AMONG MULTIPLE VARIATES (i.e. variables).

- the process of scientific inquiry: search for naturalistic regularities in phenomena  as well as their incorporation into models for subsequent testing under changed conditions. Multivariate analysis can help the process of discovery (hypothesis creation) as the process of confirmation (hypothesis testing).

- a DATA MATRIX or more DATA MATRICES are the heart of multivariate analyses. 
=> emphasize certain aspects of the association among variables at the expense of supressing less important details.

IN MULTIVARIATE ANALYSIS WE ARE INTERESTED IN ACCOUNTING FOR THE VARIATION IN ONE VARIABLE OR GROUP OF VARIABLES IN TERMS OF COVARIATION WITH OTHER VARIABLES.
=> We analyse associative data: nature and degree of association between a SET OF RESPONSE and a SET OF PREDICTOR variables, finding a function or formula by which we can estimate values of the response variables from values of predictor variables (called the regression problem), stating the statistical confidence.

In some cases we have no prior information for distinguishing between response and predictor variables. We are then interested in their interdependence as a whole. 

_________________________________________

A classification of techniques for analysing associative data

- the data matrix, which is a set of objects (m rows) and a set of measurements on those objects (the n columns). Cell entries represent the value X_ij of object i on variable j. 

- cell values may consist of continuous, discrete and categorical variables, or, standardized (their normalized, ranked, etc.  versions) or transformed versions, or combinations of these.  

- classifying multivariate techniques according to:
	- purpose of the study and types of assumptions desired by the researcher (e.g. classification, prediction, optimization, regression)
	- whole-dataset vs. datasets for groups (MANOVA vs. cluster analysis)
	- associations among variables vs. associations among objects (PCA vs. PCoA)

	- number of variables in partitioned subsets: 
			- one response variable and more predictor variables (multiple linear regression, multifactor ANOVA)
			- composites of response variables and composites of predictor variables (multifactor MANOVA)
			- composites of response variables and one predictor variable (neural networks)
			- no division in subsets at all (cluster analysis).

If we do partition the dataset we are usually concerned with the LINEAR COMPOSITES OF THE VARIABLES IN THAT SUBSET AND EACH COMPOSITE'S ASSOCIATION WITH OTHER VARIABLES. 
If we choose association of variables, most multivariate analyses assume linear relationships among the variables. A LINEAR MODEL IS OFTEN A GOOD APPROXIMATION TO A NONLINEAR ONE, AT LEAST OVER RANGES OF THE VARIABLES IN QUESTION.

The above classification criteria result in four major subdivisions of interest:

- single response, multiple predictor association: multiple regression analysis, analysis of variance and covariance, and two-group discriminant analysis

- multiple response, multiple predictor association: canonical correlation, multiple  MANOVA and MANCOVA, and multiple discriminant analysis

- analysis of variables interdependence: factor analysis, PCA

- analysis of interobject similarity: cluster analysis and other types of object-grouping procedures.

The first two categories  => dependence structures (response and predictor variables).
The last two categories => interdependence either of variables or objects. 

WITHIN EACH OF THE ABOVE CATEGORIES, VARIOUS TECHNIQUES ARE DIFFERENTIATED IN TERMS OF THE TYPE OF THE VARIABLES!!!


1) Single response, multiple predictor association

- dataset: we have n variables, of which 1 variable is the response variable, the rest of the variables (n-1) are the predictor variables

- this is a prototypical application of MULTIPLE REGRESSION in which one tries to predict values of the response variable from a linear composite (linear combination) of the predictors

- predictors can be either continuous or dummies
- the response variable can be also continuous or could represent the PRIOR CATEGORISATION OF THE RESPONSE VARIABLE based on some classification rule and dummy coded. If our purpose is to develop a linear composite (linear combination) of the predictors that enables us to classify each individual in either category, then we would employ two- (or more) group DISCRIMINANT ANALYSIS.

2) Multiple response, multiple predictor association

   
    
