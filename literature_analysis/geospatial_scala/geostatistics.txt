Working through "Geostatistics for Environmental Scientists" (R. Webster, M.A. Oliver) 2007


Author: Roxana Tesileanu, roxana.te@web.de
Affiliation: INCDS, BV
Date: October 2017

Chapter 1: INTRODUCTION

- the environment is continuous, but in general we can afford to measure properties at only a finite number of places
-> the best we can do is to estimate, or predict, in a spatial sense.
-> this is the reason we use geostatistics; it allows us to deal with properties that vary in ways that are far from systematic and at all spatial scales. 

GEOSTATISTICS CAN NEVER PROVIDE COMPLETE INFORMATION, BUT, GIVEN THE DATA, IT CAN ENABLE YOU TO ESTIMATE THE PROBABILITIES THAT THE TRUE DATA ARE WITHIN SOME SPECIFIED BOUNDS. 
__________________________________________

Generalizing:  
The environment extends more or less continuously in two dimensions. It varies from place to place beeing marked by complex interrelated processes (panarchy of processes at fast to slow paces and from small to large scales). 
Obvious properties can be analysed from aerial photos or satellite imagery, others like soil properties cannot. For the later ones we rely on measurements and analysis of samples.

BY DESCRIBING THE VARIATION AT DIFFERENT SPATIAL RESOLUTIONS WE CAN OFTEN GAIN INSIGHT INTO THE PROCESSES AND FACTORS THAT CAUSE OR CONTROL IT, AND SO PREDICT IN A SPATIAL SENSE AND MANAGE RESOURCES.

An additional issue in geospatial analysis is that AT SOME SCALE THE VALUES OF PROPERTIES ARE AUTOCORRELATED.
Places close to one another tend to have similar values, whereas ones that are farther apart differ more on average. We have to QUANTIFY THE SPATIAL AUTOCORRELATION AT THE SCALE OF INTEREST! 

Reasons for geostatistics: description, explanation and control.

Description:
- classical surveys: data are summarized by means, medians, modes, variances, skewness, cummulative frequency distribution and histograms, box-plots. 
- geostatistical surveys: similarly + SPATIAL CORRELATION
This is represented by the EXPERIMENTAL OR SAMPLE VARIOGRAM. 
In a variogram the variance is estimated at increasing intervals of distance and several directions. Alternatively, it may be the corresponding set of spatial covariances or autocorrelation coefficients. 
In addition, we should plot the sampling points on a map ("posting"). This will show the extent to which the sample fills the region of interest, any clustering, and any obvious mistakes in recording the positions such as reversed coordinates. 

Interpretation:
- we draw the variogram, we fit the model. 
- we interpret them. Show how the properties change with distance (variograms for different directions). 
- interpret in a spatial sense.   

Control:
- the idea of controlling a process is often central in time-series analyses (also plagued by autocorrelation - temporal autocorrelation this time). 
- the results of the analysis are used to change the process itself (classic control) or decisions (where you cannot control the process as soil properties cannot be altered, they are given).

History of geostatistics:
- roots in mining, petroleum extraction, agronomy and forestry. 
Nowadays we find it in many fields from petroleun engineering, hydrogeology, meteorology, soil science, agriculture, pollution, fisheries to environmental protection. 

_______________________________________________

Chapter 2: BASIC STATISTICS

- basic quantitative methods for obtaining and summarizing information on the environment: the choice of variables and how to sample the environment.

- how these records can be used for estimation, prediction and mapping.
- in general  numerical variables and categorical variables (called "indicators" in geostat.)

ANOTHER FEATURE OF ENVIRONMENTAL DATA IS THAT THEY HAVE SPATIAL AND TEMPORAL COMPONENTS AS WELL AS RECORDED VALUES !
-> we distinguish MEASUREMENT, LOCATION and TIME. 

On the notation:
-x = {x1, x2} is a vector of the two spatial coordiantes
- Z(x) , bold x, means a random variable Z at place x,
- z(x) is the actual value of Z at place x.
- Greek letters for parameter notation and their ^ ("hat" versions) for their estimates.
  
   
Spatial aspects: 
- check how the variables behave at least in the directions of the axes of the coordinate system 
-> express spatial variation 
- use stratified sampling and see how the within-stratum variance is compared to the total variance.IF THERE IS SPATIAL DEPENDENCE -> WITHIN-STRATUM VARIANCE IS LESS THAN THAT OF A SIMPLE RANDOM SAMPLE FOR THE SAME EFFORT! (see more on p. 33). 
- use systematic sampling - for a more even cover use two-dimensional grids.
The problem is that we eliminate randomization, once we chose a starting point. So, the whole discussion on variance and standard error using tables falls out of discussion. An approximation may be obtained by dividing the region into strata and computing the pooled within-stratum variance as if sampling were random within the strata. The result will almost certainly be an overestimate (thus, conservative).

@bear pop. size estimation: find out shapes of the density stata, then randomly peak hunting units within strata. At the end multiply each stratum mean by a weight (the prop. of area from the total area) and see what you get for a mean computed based on these stratum means. For the variance, also compute the pooled within-stratum variance (W.&O.p. 34). You can get estimates of the within-class variance also my means of ANOVA. PS: You should actually use sampling units of equal sizes not hunting units. so,.. 

Alternatives: Yate's method of balanced differences.
Estimates of error by balanced differences are computed as follows:
- consider sampling on a transect (i.e. systematic sampling in one direction).  
- the transect is viewed through a small window containing, say, m sampling points with values z_1, z_2, ....., z_m. Then, we compute for the window the differences:

d_m = 1/2 z_1 - z_2 + z_3 - z_4 + ... + 1/2 z_m

We then move the window along the transect in steps and compute d_m at each new position (moving window analysis). The halves of z_1 and z_m are because you start each new window at the last z of the precedent window. But, I guess we can perform it by using the middle value of the current window as starting point for the next window. Anyway, for the above eq. the variance for the transect mean is the sum s^2(balanced differences) = (1/(J(m-2+0.5)))*sum(d^2) (p. 34). J is the number of steps of the window, and (m-2+0.5) is the sum of squares of the coefficients in the eq. on d_m.    

For a two-dimensional grid the window is squared. You carefully assign the coeff. of each cell and apply the s^2(balanced differences) eq. 
THIS KIND OF WINDOWS IN ONE AND TWO DIMENSIONS FILTER OUT THE LONG-RANGE FLUCTUATION, JUST AS STRATIFICATION. (because it acts like a local variance so to speak).
Garrard's moving window analyses really help a lot!

Soil classification: use the classes to stratify the region of interest!

IN GENERAL USE CERTAIN ATTRIBUTES TO STRATIFY A REGION OF INTEREST! (this is how I've got the idea for @bear population size estimation, I've used the bear density as a criterion) 

- you obtain REGIONAL MEAN: if the classification is good, then the poolen within-stratum variance of the region is smaller than the total variance. Classification should improve the precision or efficiency in estimating the regional mean.
- the mean mu is estimated as sum(w_k*z_meank). the w_k = (area of stratum k)/ (total area). z_meank is the estimated mean for kth stratum.  
- the estimated variance is: see p. 35.

THE AVERAGE WITHIN-CLASS VARIANCE CAN BE ESTIMATED FROM DATA BY ANOVA. IT CAN ALSO SERVE FOR PREDICTION. see next ch.
      

Chapter 3: PREDICTION AND INTERPOLATION

- spatial interpolation: measurements on the environment constitute a sample from a continuum that cannot be recorded everywhere. But we would like to have values also in the area in the intervening space: predict in a spatial sense. We also want a map of the spatial distribution of the variables => GEOSTATISTICAL PREDICTION CALLED KRIGING.

!!! NEARLY ALL THE METHODS OF PREDICTION, INCLUDING THE SIMPLER FORMS OF KRIGING, CAN BE SEEN AS WEIGHTED AVERAGES OF DATA !!!

-> such weighted averages look like Andrew's neural networks.
an estimated value at a target point x_0 is: the sum of all values measured weighted by lambda (each value has its own weight): z(x_0) = sum(lambda_i*z(x_i)).
          
How are these weights assigned?
- Thiessen polygons (Voronoi polygons, Dirichlet tessellation): 
lambda_i= 1 if x_i included in Vi (its tile) OR ELSE lambda_i = 0.

- Triangulation: 
determines the value lambda_1 from the apices of the triangle formed by {x_11, x_12}, {x_21, x_22} and {x_31, x_32}  and those of the target point {x_01, x_02} by linear interpolation. It applies the same procedure to lambda_2 and lambda_3.

@alternative: if you have a target point P1 for which you want to estimate the value for a variable you can use the 3 nearest neighbors P2, P3, and P4.
 The nearest neighbors are represented by the 3 neighbors which have the smallest distance to the target point, where the distance between P1 and P2 is given by d= sqrt( (x_2 - x_1)^2 + (y_2 - y_1)^2), i.e. Pythagora or the magnitude from M. Lewis videos, and the same for P1 and P3, and P1 and P4. 
If we add these distances to a total, we can find out the weight each neighbor receives in estimating the value for P1 by subtracting the result of dividing each distance to the total distance from 1, i.e. (1-(d_P1P2/d_total)).
 Also the local variance can give us a measure of how sure we are about the prediction. I have to test this idea on a DEM to see if I have a grid of elevation values and compute the nearest neighbors how well does it fit to the data.   



- Natural neighbor interpolation:
    
---------------------------------------------------------------

"Applied Geostatistics" Edward H. Isaaks, R. Mohan Srivastava


 
  
    
